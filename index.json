[{"content":"","date":"3 March 2023","permalink":"/blog/","section":"Blog","summary":"","title":"Blog"},{"content":"","date":"3 March 2023","permalink":"/tags/nix/","section":"Tags","summary":"","title":"nix"},{"content":"In this quick blogpost I want to show how you can setup a rustup toolchain with nix. Instead of using the rustup cli app, we will be fetching the toolchains directly with nix.\nWhy do we want to do this, instead of just adding rustup to our environment.systemPackages or to a shell? rustup is a program that will fetch the toolchain from the internet, and as you may already know, fetching binaries from the internet is bound to fail at some point in NixOS.\nAnother nicety that we get, is that we can use nix flake\u0026rsquo;s locking system, so that everybody that develops the projects (and CI too!) will get the same toolchain version.\nrust-toolchain # The rust-toolchain or toolchain.toml is a file used by rustup that declares what channel to use, which components, targets, etc. This file lives in the root of the repo. Oxalica\u0026rsquo;s rust-overlay then would read this file, and produce the required nix derivation according to the requirements.\nSo instead of running rustup, we just point the overlay to rustup\u0026rsquo;s config file. Nice and easy.\nAn example of this file:\n# toolchain.toml [toolchain] channel = \u0026#34;nightly\u0026#34; components = [ \u0026#34;rustfmt\u0026#34;, \u0026#34;rust-src\u0026#34; ] profile = \u0026#34;minimal\u0026#34; Classic nix # This approach uses nix channels and fetchTarball, to get whatever overlay version is the latest. We don\u0026rsquo;t lock the overlay version, and it is as simple as it can get.\nTo use the shell, just run nix-shell\n# shell.nix let rust-overlay = builtins.fetchTarball \u0026#34;https://github.com/oxalica/rust-overlay/archive/master.tar.gz\u0026#34;; pkgs = import \u0026lt;nixpkgs\u0026gt; { overlays = [(import rust-overlay)]; }; toolchain = pkgs.rust-bin.fromRustupToolchainFile ./toolchain.toml; in mkShell { packages = [ toolchain ]; } Flakes # By using a flake, we are able to lock the version of the rust overlay, so we always get the same version of the toolchain, for a given flake.lock. This is incredibly useful to avoid \u0026ldquo;it works on my machine\u0026rdquo;, by having every developer and CI use the same toolchain version, according to the specification of the rustup config.\nTo enter the shell, just run nix develop\n{ inputs = { nixpkgs.url = \u0026#34;github:NixOS/nixpkgs/nixos-unstable\u0026#34;; rust-overlay.url = \u0026#34;github:oxalica/rust-overlay\u0026#34;; }; outputs = { self, nixpkgs, rust-overlay, }: let system = \u0026#34;x86_64-linux\u0026#34;; pkgs = import nixpkgs { inherit system; overlays = [rust-overlay.overlays.default]; }; toolchain = pkgs.rust-bin.fromRustupToolchainFile ./toolchain.toml; in { devShells.${system}.default = pkgs.mkShell { packages = [ toolchain ]; }; }; } rust-analyzer # For rust-analyzer to work properly, you will need to setup the environment variable RUST_SRC_PATH, which must point to a subdirectory of our toolchain. To do so, just modify your mkShell definition (flakes or not) such as:\n# ... pkgs.mkShell { packages = [ toolchain # We want the unwrapped version, wrapped comes with nixpkgs\u0026#39; toolchain pkgs.rust-analyzer-unwrapped ]; RUST_SRC_PATH = \u0026#34;${toolchain}/lib/rustlib/src/rust/library\u0026#34;; } Finally, make sure you include the rust-src component in your rustup toolchain definition:\n# toolchain.toml [toolchain] components = [ \u0026#34;rust-src\u0026#34; # ... ] ","date":"3 March 2023","permalink":"/blog/nix-rustup/","section":"Blog","summary":"Quick guide to fetching your rustup toolchains with nix","title":"Nix shell with rustup"},{"content":"Congo has full support for Hugo taxonomies and will adapt to any taxonomy set up. Taxonomy listings like this one also support custom content to be displayed above the list of terms.\nThis area could be used to add some extra descriptive text to each taxonomy. Check out the advanced tag below to see how to take this concept even further.\n","date":"3 March 2023","permalink":"/tags/","section":"Tags","summary":"Congo has full support for Hugo taxonomies and will adapt to any taxonomy set up.","title":"Tags"},{"content":" My name is Fernando Ayats and I am a student finishing my master\u0026rsquo;s degree in Computing Research. I finished my bachelor\u0026rsquo;s degree in Aerospace Engineering in the Navigation System\u0026rsquo;s specialisation, with my thesis consiting in programming a flight simulator and integrating it with HIL systems at Aurea Avionics.\n","date":"3 March 2023","permalink":"/","section":"Welcome to Congo! üéâ","summary":"My name is Fernando Ayats and I am a student finishing my master\u0026rsquo;s degree in Computing Research.","title":"Welcome to Congo! üéâ"},{"content":"This a quick tutorial about filtering a flake\u0026rsquo;s self set to avoid unnecessary recompilation.\nWhy do we need to filter a source tree? # When we build derivations with nix, it automatically calculates a hash out of the derivations\u0026rsquo;s inputs. When we have a flake that outputs a package, one of these inputs is the files themselves contained in the flake. Therefore, any change to the flake\u0026rsquo;s source tree, will have nix recompute the hash of that input, which will be different.\nBut there are changes that shouldn\u0026rsquo;t influence these input hashes. For example adding a comment to your flake.nix. For this reason, we will filter out everything that is not needed for a package build, so we trigger recompilations only when needed. On a first approach, we can filter out nix files, but for language spcecific projects, we could narrow it down.\nHow does an unfiltered flake look like? # In your conventional flake that outputs some package, you will have a layout that can be reduced to something like the following:\n{ inputs = { nixpkgs.url = \u0026#34;github:NixOS/nixpkgs/nixos-21.11\u0026#34;; }; outputs = {self, nixpkgs}: { packages.x86_64-linux.default = nixpkgs.legacyPackages.x86_64-linux.stdenv.mkDerivation { src = self; # or another variant: # src = ./.; # ... }; }; } By default, whether we use self (which resolves to self.outPath) or ./., we will be including our flake.nix, flake.lock or any other \u0026ldquo;nixfiles\u0026rdquo; in our src.\nIntroducing numtide/nix-filter # To perform a source filter, there are several solutions, including built-in functions. But in this post I propose numtide\u0026rsquo;s nix-filter. It is a solution which is very convenient to use and provides some utility functions.\nTo use nix-filter in out previous flake, we can pull their flake and use nix-filter.lib:\n{ inputs = { nixpkgs.url = \u0026#34;github:NixOS/nixpkgs/nixos-21.11\u0026#34;; nix-filter.url = \u0026#34;github:numtide/nix-filter\u0026#34;; }; outputs = {self, nixpkgs, nix-filter}: { packages.x86_64-linux.default = nixpkgs.legacyPackages.x86_64-linux.stdenv.mkDerivation { src = nix-filter.lib { root = self; exclude = [ (nix-filter.lib.matchExt \u0026#34;nix\u0026#34;) \u0026#34;flake.lock\u0026#34; ]; }; # ... }; }; } ","date":"29 December 2022","permalink":"/blog/nix-filter/","section":"Blog","summary":"Quick tutorial about filtering a flake\u0026rsquo;s self attribute, to avoid unnecessary recompilation.","title":"Filtering flake's self"},{"content":"Declarative Ubuntu # \u0026ldquo;Add this PPA to be aple to install some package\u0026hellip;\u0026rdquo;\n\u0026ldquo;Enable foo.service, and write this to /etc/some/path/to/be/forgotten \u0026hellip;\u0026rdquo;\nEvery undocumented action we do into our systems, nears them into an more unknown state. Even if these modifications are very clear in the present, will you remember about them in a few weeks? What about other people that work on the same system?\nLike a vacuum cleaner, the OS collects \u0026ldquo;state\u0026rdquo;, that we could define as modifications from the original system, that are the result of commands ran by humans, or by its autonomous operations. Of course, there is some state that we are are interested in: the database of our application, its logs, etc. But should every single file on the disk, be able to aquire state? I wouldn\u0026rsquo;t say so.\nFor Linux, the elephant in the room is /etc. Citing the FHS:\n/etc : Host-specific system configuration\nPurpose: The /etc hierarchy contains configuration files. (\u0026hellip;)\nWith such a vague definition, what I take a way is Host-specific, as in configuration files that are only needed for my specific system. Therefore, a default Linux system would come with an empty /etc, and it would be filled with configuration files as we use it and manually configure it!\nThis is far from the reality, as with a quick look into any Linux distribution we see a lot of non-host-specific configuration files. The question then is, which of these files were modified by me, and which came preinstalled?\nThe solution that I propose is having a system, where the user\u0026rsquo;s configuration files are not mixed with the default configuration files. With a system like this, the problem of \u0026ldquo;collecting state\u0026rdquo; vanishes: every file from my distro can be safely wiped and recreated, as it is \u0026ldquo;stateless\u0026rdquo;, and combined with my \u0026ldquo;configuration\u0026rdquo; it results in the system.\nBecause of how /etc is layed out in current distros won\u0026rsquo;t change any time soon, the key concept that glues this together is: indiscriminate removal of state. Wiping everything in the filesystem, and rebuilding the system for scratch on a weekly or monthly basis can help us prevent the problem of accumulating \u0026ldquo;state\u0026rdquo;, undocumented changes to the system.\nApt metapackage # The most straightforward solution could be to set up a metapackage, such that everything in the system, is ultimately a dependency of this metapackage.\nFor example:\nconfiguration.deb Depends on: every installed package that you want in your system. Includes every modification to /etc Therefore, the entire system is the result of installing it, into a \u0026ldquo;blanket\u0026rdquo; system. The administration workflow is converted:\nInstalling packages into adding as a dependency to out metapackage Modifying files in /etc or with commands into modifying the source of the metapackage. As everything can be reproduced* by this package, we can discard the entire filesystem every week or month, to make sure it doesn\u0026rsquo;t collect state (modifications to this configuration, not tracked by the metapackage). In any case, you may want to keep *some* state, like some subfolder of /var or /home. For my experiment, I used ZFS subvolumes that get mounted into these locations.\nstage0, stage1, stage2 # For Ubuntu specifically, I came up with 3 steps. Ideally we would have just 1 step, such that the system can be installed from an empty tree.\nMinimal Ubuntu debootstrap (stage 0) stage1.deb, configures apt before installing more packages stage2.deb installs every dependency of the system, and every configuration file You can find the source code for the experiment in github.com/viperML/ubuntu-declarative, so I don\u0026rsquo;t copy-paste everything into this blog.\nThe folder structure is as follows:\n‚îú‚îÄ‚îÄ stage1 ‚îÇ ‚îú‚îÄ‚îÄ DEBIAN ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ control ‚îÇ ‚îî‚îÄ‚îÄ etc ‚îÇ ‚îî‚îÄ‚îÄ apt ‚îÇ ‚îú‚îÄ‚îÄ apt.conf.d ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ 00stage1 ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ 99release ‚îÇ ‚îú‚îÄ‚îÄ preferences.d ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ stage1 ‚îÇ ‚îú‚îÄ‚îÄ sources.list.d ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ graphics-drivers-ubuntu-ppa.list ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ microsoft.list ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ release.list ‚îÇ ‚îî‚îÄ‚îÄ trusted.gpg.d ‚îÇ ‚îú‚îÄ‚îÄ graphics-drivers-ubuntu-ppa.gpg ‚îÇ ‚îî‚îÄ‚îÄ microsoft.gpg ‚îú‚îÄ‚îÄ stage1.deb The control file, would have the contents:\nPackage: stage2 Version: 1.0.1 Architecture: amd64 Maintainer: Anonymous Description: No description Depends: linux-generic, linux-image-generic, linux-headers-generic, linux-firmware, cryptsetup, dracut, zfs-dracut, keyboard-configuration, console-setup, console-setup-linux, kbd, iproute2, network-manager, sudo, vim, curl, git, man, manpages, strace, neofetch, software-properties-common, nvidia-driver-510, kde-plasma-desktop, kubuntu-wallpapers, plasma-nm, ark, flatpak, nix-setup-systemd, code This metapackages can be trivially built with\ndpkg-deb --build --root-owner-group stage1 stage1.deb Setting up the users # Instead adding your user imperatively, or as some post-install hook, you can use systemd-sysusers to automatically add your user:\n# stage2/etc/sysusers.d/ayats.conf u ayats 1000:100 \u0026#34;Fernando Ayats\u0026#34; /home/ayats /usr/bin/bash This won\u0026rsquo;t set any password, but you can also set automatic login to tty or your display manager:\n# stage2/etc/systemd/system/getty@.service.d/autologin.conf [Service] X-RestartIfChanged=false ExecStart= ExecStart=@/usr/sbin/agetty agetty \u0026#39;--login-program\u0026#39; \u0026#39;/usr/bin/login\u0026#39; \u0026#39;--autologin\u0026#39; \u0026#39;ayats\u0026#39; --noclear --keep-baud %I 115200,38400,9600 $TERM # stage2/etc/sddm.conf.d/autologin.conf [Autologin] User=ayats Session=plasma Bootloader and initrd # For my specific hardware, this took longer than expected. From my very little experience, it seems that the default initramfs that Ubuntu comes with, uses a script that tries to get information from the running system to build it. As I was building it from a Docker image, chrooted into the filesystem tree, it failed pretty quickly.\nMy solution was to use dracut, and making sure it builds a generic initramfs to boot.\nAs for the bootloader, I didn\u0026rsquo;t install any, as my EFI partition already had systemd-boot working. So a script was tasked with copying the kernels and initrd\u0026rsquo;s into the ESP, and adding the boot entry.\nClosing thoughts # Just by having all the configuration in a monorepo, instead of running imperative commands, we gain some features for free. For example, having the system git-tracked allows us to know when we made some change, revert it, or even share it with other people to help debug some problem.\nWith the advent of Fedora Silverblue, being claimed as an \u0026ldquo;immutable\u0026rdquo; distro, isn\u0026rsquo;t it also prone to having a dirty /etc, with mixed host-specific and non-host-specific files? What is immutable about that? Moreover, is our experiment \u0026ldquo;more immutable\u0026rdquo;? Given that it can\u0026rsquo;t be modified, as any modification is easily reverted by reconstructing it from scratch.\nIf you like this concept, give NixOS a try, as this way of managing the system is the default. By using symlinks, it can recreate the root filesystem from scratch, without any prior knowledge of what is in /etc .\n","date":"19 June 2022","permalink":"/blog/declarative-ubuntu/","section":"Blog","summary":"Experiment to have a Ubuntu installation managed declaratively, instead of imperatively","title":"Declarative Ubuntu"},{"content":"","date":"19 June 2022","permalink":"/tags/ubuntu/","section":"Tags","summary":"","title":"ubuntu"},{"content":"From channels to flakes # This post serves as a quick tutorial for anyone running NixOS or home-manager with a flake. Your flake will have an input for the nixpkgs flake, that gets pinned to a specific commit in your flake.lock. For example:\n{ inputs.nixpkgs.url = \u0026#34;github:NixOS/nixpkgs/nixos-22.05\u0026#34;; # ... } { \u0026#34;nodes\u0026#34;: { \u0026#34;nixpkgs\u0026#34;: { \u0026#34;locked\u0026#34;: { \u0026#34;lastModified\u0026#34;: 1655456688, \u0026#34;narHash\u0026#34;: \u0026#34;sha256-j2trI5gv2fnHdfUQFBy957avCPxxzCqE8R+TOYHPSRE=\u0026#34;, \u0026#34;owner\u0026#34;: \u0026#34;NixOS\u0026#34;, \u0026#34;repo\u0026#34;: \u0026#34;nixpkgs\u0026#34;, \u0026#34;rev\u0026#34;: \u0026#34;d17a56d90ecbd1b8fc908d49598fb854ef188461\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;github\u0026#34; }, \u0026#34;original\u0026#34;: { \u0026#34;owner\u0026#34;: \u0026#34;NixOS\u0026#34;, \u0026#34;ref\u0026#34;: \u0026#34;nixos-22.05\u0026#34;, \u0026#34;repo\u0026#34;: \u0026#34;nixpkgs\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;github\u0026#34; } }, // ... $ jq -r \u0026#39;.nodes.nixpkgs.locked.rev\u0026#39; \u0026lt; flake.lock d17a56d90ecbd1b8fc908d49598fb854ef188461 This is very nice! Our system will have a known nixpkgs rev. But there are applications, that are not built as part of the flake, that will consume the nixpkgs flake. You probably want to propagate this rev to your whole system, so everything uses it by default.\nUsing a different nixpkgs rev of you system, will have some undesirable effects, ranging from pulling megabytes of packages to using some old channel that you forgot you had.\nSome examples of commands that won‚Äôt use this nixpkgs rev of your flake, include:\nnix-shell -p \u0026lt;package\u0026gt; nix run nixpkgs#\u0026lt;package\u0026gt; Any nix code that uses import \u0026lt;nixpkgs\u0026gt; {} nix-env -iA \u0026lt;package\u0026gt; (you don‚Äôt want nix-env anyways‚Ä¶‚Äã) We can classify these in:\nTools that use channels and NIX_PATH Tools that query the flake registry So, for each problem we will have a different solution. I have included how to do it for both NixOS and home-manager. Just pick whatever you need, or use both at the same time!\nPinning your channels # Pre-flake nix tools use the environment variable NIX_PATH to query the location of some downloaded nixpkgs in your disk, which in turn is populated by the nix-channel tool. So the usual workflow is as follows:\nThe user adds nixpkgs as a channel with nix-channel --add nixpkgs is then downloaded into the disk into a special location. This location is by default in the NIX_PATH environment variable. Cli tools query the environment variable to know where to find it. You may also have encountered the usage of NIX_PATH in nix code, with the usage of the diamond-path operator:\nwith import \u0026lt;nixpkgs\u0026gt; {}; To query the path to which \u0026lt;nixpkgs\u0026gt; resolves to, you can use $ nix eval --impure --expr \u0026quot;\u0026lt;nixpkgs\u0026gt;\u0026quot;\nSo, the easiest solution is to set the value NIX_PATH to whatever nixpkgs our flake uses. In the process, we will also create ‚Äúproxy‚Äù links (/etc/nix/inputs/nixpkgs and ~/.config/nix/inputs/nixpkgs), so we can safely update it without reloading the environment.\n{ outputs = { self, nixpkgs, home-manager, }: { nixosConfigurations.HOSTNAME = nixpkgs.lib.nixosSystem { # ... modules = [ { environment.etc.\u0026#34;nix/inputs/nixpkgs\u0026#34;.source = nixpkgs.outPath; nix.nixPath = [\u0026#34;nixpkgs=/etc/nix/inputs/nixpkgs\u0026#34;]; } ]; }; homeConfigurations.USER = home-manager.lib.homeManagerConfiguration { # ... modules = [ (args: { xdg.configFile.\u0026#34;nix/inputs/nixpkgs\u0026#34;.source = nixpkgs.outPath; home.sessionVariables.NIX_PATH = \u0026#34;nixpkgs=${args.config.xdg.configHome}/nix/inputs/nixpkgs$\\{NIX_PATH:+:$NIX_PATH}\u0026#34;; }) ]; }; }; } After rebuilding, check if your nixpkgs was inserted into NIX_PATH:\n$ printenv NIX_PATH nixpkgs=/home/\u0026lt;user\u0026gt;/.config/nix/inputs/nixpkgs $ readlink -f $HOME/.config/nix/inputs/nixpkgs /nix/store/\u0026lt;hash\u0026gt;-source Make sure to remove your channels afterwards, they are not needed anymore!\nPinning your registry # The new nix \u0026lt;command\u0026gt; programs now use a new method to get nixpkgs, instead of querying the NIX_PATH environment variable. Every command needs two compontents, separated with a #. For an example command such as nix shell nixpkgs#hello, it would take:\nA flake reference (flakeref): nixpkgs A flake output: hello (expaned to legacyPackages.\u0026lt;system\u0026gt;.hello) There are several types for flakerefs. In this case, the flakeref nixpkgs is indirect, that means that it queries the flake registry to resolve to a different type: github:NixOS/nixpkgs/nixpkgs-unstable.\nSo, if we want the flakeref nixpkgs to use the same commit as we use in our flake, the solution is to modifiy the flake regitry, so it resolves to our nixpkgs rev.\n{ outputs = { self, nixpkgs, home-manager, }: { nixosConfigurations.HOSTNAME = nixpkgs.lib.nixosSystem { # ... modules = [ { nix.registry.nixpkgs.flake = nixpkgs; } ]; }; homeConfigurations.USER = home-manager.lib.homeManagerConfiguration { # ... modules = [ { nix.registry.nixpkgs.flake = nixpkgs; } ]; }; }; } After rebuilding, you can query your registry to see if it is in effect:\n$ nix registry list user flake:nixpkgs path:/nix/store/\u0026lt;hash\u0026gt;-source\u0026lt;...\u0026gt; # ... ","date":"12 February 2022","permalink":"/blog/channels-to-flakes/","section":"Blog","summary":"How to to manage the global flake registry, and use flakes with channels","title":"Channels to flakes"},{"content":"","date":"29 January 2022","permalink":"/tags/cloud/","section":"Tags","summary":"","title":"cloud"},{"content":"In this post I want to show you how I set up a NixOS server running a private Gitea instance, with CI pipelines using Drone, all tied together with Nginx, PostgreSQL and sops-nix. With this setup you would have:\nA private Git repository to upload your projects, with a nice web interface. CI/CD pipelines, with a similiar behaviour to GitHub\u0026rsquo;s or Gitlab\u0026rsquo;s. This guide is also oriented at a hobbist setup, where the approach is to keep the configuration as simple as posible.\nServer # This guide assumes that you already have a machine to deploy your NixOS configurations to, and that you have a working minimial configuration. To do so, there are some NixOS-native projects that can help you, such as:\nNixOps deploy-rs (check out my guide here) Whichever solution you use, you can adapt and drop this configuration files, and then import them from your main configuration.nix.\nsops-nix # To deploy secrets to our machine, we could think of these options:\nWrite our secrets directly into configuration.nix Write our secrets into a file in the machine, (such as /secret/my-secret), and reference that file in configuration.nix sops-nix uses a hybrid approach: our secrets will be stored encrypted in our configuration. When the machine boots up, it try to decrypt them using the age key, and put them into a specific path (config.sops.secrets.\u0026lt;my-secret\u0026gt;.path).\n{ config, pkgs, ... }: { sops.age.keyFile = \u0026#34;/secrets/age/keys.txt\u0026#34;; } If you prefer to configure your secrets in another way, make sure to replace the lines that use sops with your solution. However, if you want to use sops, read the upstream documentation to get started.\nGitea # NixOS provides a module to setup Gitea. We only need to add the postgres configuration, and our password via sops. Note that this configuration was taken by this post by Craige McWhirter, without much modification.\nThe service will listen on the port 3001, where it will receive the http requests forwarded by nginx.\n{ config, pkgs, ... }: { services.nginx.virtualHosts.\u0026#34;git.my-domain.tld\u0026#34; = { enableACME = true; forceSSL = true; locations.\u0026#34;/\u0026#34; = { proxyPass = \u0026#34;http://localhost:3001/\u0026#34;; }; }; services.postgresql = { authentication = \u0026#39;\u0026#39; local gitea all ident map=gitea-users \u0026#39;\u0026#39;; identMap = # Map the gitea user to postgresql \u0026#39;\u0026#39; gitea-users gitea gitea \u0026#39;\u0026#39;; }; sops.secrets.\u0026#34;postgres/gitea_dbpass\u0026#34; = { sopsFile = ../.secrets/postgres.yaml; # bring your own password file owner = config.users.users.gitea.name; }; services.gitea = { enable = true; appName = \u0026#34;My awesome Gitea server\u0026#34;; # Give the site a name database = { type = \u0026#34;postgres\u0026#34;; passwordFile = config.sops.secrets.\u0026#34;postgres/gitea_dbpass\u0026#34;.path; }; domain = \u0026#34;git.my-domain.tld\u0026#34;; rootUrl = \u0026#34;https://git.my-domain.tld/\u0026#34;; httpPort = 3001; }; } Drone # Drone is a piece of software that will perform our CI/CD pipelines. It is very similiar to how GitHub\u0026rsquo;s actions or Gitlab\u0026rsquo;s pipelines work, so:\nWe create a .drone.yml file in the root of a repository. This file defines some job(s) to execute under certain conditions, such as this example: --- kind: pipeline type: exec name: deploy platform: os: linux arch: amd64 steps: - name: main-step environment: MY_SECRET: from_secret: MY_SECRET commands: - nix run .#run-my-app Gitea\u0026rsquo;s web interface will detect our jobs, and show a symbol with the job status, and a shortcut to Drone\u0026rsquo;s control panel. To configure this, we need at least two components:\nThe server: will communicate between Gitea and the runners The runners: will perform the builds. There are a many runners , but in this example I set-up two of them: Docker runner, to run jobs inside docker containers Exec runner, to use the server\u0026rsquo;s nix store (this results in cached results, environments, etc) As there is no Drone module at the time of writing, I configured these systemd services based on Mic92\u0026rsquo;s dotifiles:\n{ config, pkgs, ... }: let droneserver = config.users.users.droneserver.name; in { users.users.droneserver = { isSystemUser = true; createHome = true; group = droneserver; }; users.groups.droneserver = { }; services.nginx.virtualHosts.\u0026#34;drone.my-server.tld\u0026#34; = { enableACME = true; forceSSL = true; locations.\u0026#34;/\u0026#34;.proxyPass = \u0026#34;http://localhost:3030/\u0026#34;; }; services.postgresql = { ensureDatabases = [ droneserver ]; ensureUsers = [{ name = droneserver; ensurePermissions = { \u0026#34;DATABASE ${droneserver}\u0026#34; = \u0026#34;ALL PRIVILEGES\u0026#34;; }; }]; }; # Secrets configured: # - DRONE_GITEA_CLIENT_ID # - DRONE_GITEA_CLIENT_SECRET # - DRONE_RPC_SECRET # To get these secrets, please check Drone\u0026#39;s documentation for Gitea integration: # https://docs.drone.io/server/provider/gitea/ sops.secrets.drone = { sopsFile = ../.secrets/drone.yaml; }; systemd.services.drone-server = { wantedBy = [ \u0026#34;multi-user.target\u0026#34; ]; serviceConfig = { EnvironmentFile = [ config.sops.secrets.drone.path ]; Environment = [ \u0026#34;DRONE_DATABASE_DATASOURCE=postgres:///droneserver?host=/run/postgresql\u0026#34; \u0026#34;DRONE_DATABASE_DRIVER=postgres\u0026#34; \u0026#34;DRONE_SERVER_PORT=:3030\u0026#34; \u0026#34;DRONE_USER_CREATE=username:viperML,admin:true\u0026#34; # set your admin username \u0026#34;DRONE_GITEA_SERVER=https://git.my-domain.tld\u0026#34; \u0026#34;DRONE_SERVER_HOST=drone.my-domain.tld\u0026#34; \u0026#34;DRONE_SERVER_PROTO=https\u0026#34; ]; ExecStart = \u0026#34;${pkgs.drone}/bin/drone-server\u0026#34;; User = droneserver; Group = droneserver; }; }; ### Docker runner users.users.drone-runner-docker = { isSystemUser = true; group = \u0026#34;drone-runner-docker\u0026#34;; }; users.groups.drone-runner-docker = { }; # Allow the runner to use docker users.groups.docker.members = [ \u0026#34;drone-runner-docker\u0026#34; ]; systemd.services.drone-runner-docker = { enable = true; wantedBy = [ \u0026#34;multi-user.target\u0026#34; ]; ### MANUALLY RESTART SERVICE IF CHANGED restartIfChanged = false; serviceConfig = { Environment = [ \u0026#34;DRONE_RPC_PROTO=http\u0026#34; \u0026#34;DRONE_RPC_HOST=localhost:3030\u0026#34; \u0026#34;DRONE_RUNNER_CAPACITY=2\u0026#34; \u0026#34;DRONE_RUNNER_NAME=drone-runner-docker\u0026#34; ]; EnvironmentFile = [ config.sops.secrets.drone.path ]; ExecStart = \u0026#34;${pkgs.drone-runner-docker}/bin/drone-runner-docker\u0026#34;; User = \u0026#34;drone-runner-docker\u0026#34;; Group = \u0026#34;drone-runner-docker\u0026#34;; }; }; ### Exec runner users.users.drone-runner-exec = { isSystemUser = true; group = \u0026#34;drone-runner-exec\u0026#34;; }; users.groups.drone-runner-exec = { }; # Allow the exec runner to write to build with nix nix.allowedUsers = [ \u0026#34;drone-runner-exec\u0026#34; ]; systemd.services.drone-runner-exec = { enable = true; wantedBy = [ \u0026#34;multi-user.target\u0026#34; ]; ### MANUALLY RESTART SERVICE IF CHANGED restartIfChanged = true; confinement.enable = true; confinement.packages = [ pkgs.git pkgs.gnutar pkgs.bash pkgs.nixFlakes pkgs.gzip ]; path = [ pkgs.git pkgs.gnutar pkgs.bash pkgs.nixFlakes pkgs.gzip ]; serviceConfig = { Environment = [ \u0026#34;DRONE_RPC_PROTO=http\u0026#34; \u0026#34;DRONE_RPC_HOST=127.0.0.1:3030\u0026#34; \u0026#34;DRONE_RUNNER_CAPACITY=2\u0026#34; \u0026#34;DRONE_RUNNER_NAME=drone-runner-exec\u0026#34; \u0026#34;NIX_REMOTE=daemon\u0026#34; \u0026#34;PAGER=cat\u0026#34; \u0026#34;DRONE_DEBUG=true\u0026#34; ]; BindPaths = [ \u0026#34;/nix/var/nix/daemon-socket/socket\u0026#34; \u0026#34;/run/nscd/socket\u0026#34; # \u0026#34;/var/lib/drone\u0026#34; ]; BindReadOnlyPaths = [ \u0026#34;/etc/passwd:/etc/passwd\u0026#34; \u0026#34;/etc/group:/etc/group\u0026#34; \u0026#34;/nix/var/nix/profiles/system/etc/nix:/etc/nix\u0026#34; \u0026#34;${config.environment.etc.\u0026#34;ssl/certs/ca-certificates.crt\u0026#34;.source}:/etc/ssl/certs/ca-certificates.crt\u0026#34; \u0026#34;${config.environment.etc.\u0026#34;ssh/ssh_known_hosts\u0026#34;.source}:/etc/ssh/ssh_known_hosts\u0026#34; \u0026#34;${builtins.toFile \u0026#34;ssh_config\u0026#34; \u0026#39;\u0026#39; Host git.ayats.org ForwardAgent yes \u0026#39;\u0026#39;}:/etc/ssh/ssh_config\u0026#34; \u0026#34;/etc/machine-id\u0026#34; \u0026#34;/etc/resolv.conf\u0026#34; \u0026#34;/nix/\u0026#34; ]; EnvironmentFile = [ config.sops.secrets.drone.path ]; ExecStart = \u0026#34;${pkgs.drone-runner-exec}/bin/drone-runner-exec\u0026#34;; User = \u0026#34;drone-runner-exec\u0026#34;; Group = \u0026#34;drone-runner-exec\u0026#34;; }; }; } Note: this setup runs both Gitea and Drone in the same machine. It could be beneficial to have different machines for each service, being for performance or security reasons.\nNginx, ACME, Postgres, Docker # Finally, to tie everything together, we set up a basic Nginx service, that proxies the requests to the virtual hosts, to the internal services. Remember to punch a hole in your firewall, as by default, the firewall is enabled with the ports closed!\n{ config, pkgs, ... }: networking.firewall.allowedTCPPorts = [ 80 443 ]; services.nginx = { enable = true; recommendedGzipSettings = true; recommendedOptimisation = true; recommendedProxySettings = true; recommendedTlsSettings = true; }; security.acme = { acceptTerms = true; certs = { \u0026#34;git.my-domain.tld\u0026#34;.email = \u0026#34;foo@bar.com\u0026#34;; \u0026#34;drone.my-domain.tld\u0026#34;.email = \u0026#34;foo@bar.com\u0026#34;; }; }; services.postgresql = { enable = true; }; virtualisation.docker = { enable = true; }; } Finale # I hope that this helps you set-up your Gitea server. This write-up is based on my own configuration, with some simplifications. You can check the whole flake here: github.com/viperML/infra.If you find any errors or suggestions, please submit a issue or pull request at the repo of this blog: github.com/viperML/home.\n","date":"29 January 2022","permalink":"/blog/gitea-drone/","section":"Blog","summary":"Tutorial to get started with a self-hosted Git repo with automatic CI, as a Github/Gitlab alternative","title":"Private git repository with NixOS, Gitea and Drone"},{"content":"In this post I want to show a very brief introduction to Nix, the language and package manager, and how it can help you to achieve a fully reproducible development environment.\nWhat can Nix do for me? # One of the features of Nix is that it is designed to allow for fully reproducible software development. Let\u0026rsquo;s say you have a project, for which you want your coworkers, for yourself in the future or anybody else to be able to get the same results as you. There will be many variables that will be taken into account, such as the programs available in the host, the versions, configurations, etc; that will affect your results (for example, a built binary or a developing environment). Nix allows you not only to specify which package versions your project depends, but also the specific build which will be used. So, given the exact same inputs, Nix will produce identical results, be it in your machine, your coworkers or in a remote server.\nSo what is Nix exactly? # Nix is a purely functional programming language, dynamically typed, with a syntax very similar to JSON. Currently, the main purpose of this language is not being general purpose, but rather being the main tool of the Nix package manager.\nwith { a = 1; b = 2; }; { x = a + b }; # { x = 3; } Nix is in a strange situation, where many tutorials will try to teach you the basics semantics of the language, using arithmetics operations, handling strings, etc; but the real usage of the language is to build packages, in which these snippets might not be very useful.\npkgs.stdenv.mkDerivation { name = \u0026#34;viperML-home\u0026#34;; src = ./.; buildPhase = \u0026#39;\u0026#39; mkdir -p themes ln -s ${inputs.bookworm} themes/bookworm ${pkgs.hugo}/bin/hugo --minify \u0026#39;\u0026#39;; installPhase = \u0026#39;\u0026#39; cp -r public $out \u0026#39;\u0026#39;; meta = with pkgs.lib; { description = \u0026#34;My awesome webpage\u0026#34;; license = licenses.cc-by-nc-sa-40; platforms = platforms.all; }; This snippet of nix code may be more representative of how the Nix language can be used. It defines a derivation, which is how to build a package. While you could say that this package is called viperML-home (see name = ), the derivation name will be named differently if anything changes.\nmkDerivation is a function that creates the derivation, and takes as an argument an set of attributes, such as { foo = \u0026quot;bar\u0026quot;; foo2 = [ 1 2 ] }. name, meta define basic information about the package. buildPhase, installPhase are bash snippets, and correspond to how Nix will build the derivation. The derivation will just be a directory in /nix, with path $out, so we can just point our installers to put the files in there, and our derivation will be built. Now the nix cli utilty, will be used to call this function, and install the files into /nix/store/\u0026lt;hash\u0026gt;-\u0026lt;package\u0026gt;-\u0026lt;version\u0026gt;. Because two packages with the same version and name can have different build or installation methods, a hash is computed and put into the name. This way, any number of \u0026ldquo;editions\u0026rdquo; of this package can coexist in the same system. Using one or another will be just a task of using the correct path.\nNow, every dependency of our package will be substituted by their exact derivation path. In the example snippet before, ${pkgs.hugo}/bin/hugo will be substituted by /nix/store/7jnn3g8871yqih4m61ggbjs1dif6hksa-hugo-0.91.2/bin/hugo and this will be the same across any system that calls the expression. If the derivation for hugo changes, their hashes will be different, so my viperML-home will be built different, and produce a different hash in the store. So, going backwards, if we use the same inputs for our build process, Nix will make sure to produce the same exact result; and if we know a derivation, we know how it was built exactly.\nBut how do we make sure that Nix gets always the same inputs to build the same results?\nWhen calling that previous Nix expression, it was in a context with the pkgs variable defined. We can define this by referencing the commit of nixpkgs, the git repo from which we pull or packages. This can also be done with the upcoming feature, flakes, will will be discussed in a future post.\nHow do I start using Nix? # Nix can be used in Linux, macOS or Windows via WSL2. Link to official documentation.\nAfter installing (and rebooting) your computer, you can start using Nix with:\nnix-shell --packages python3 This pull the python package, according to the nixpkgs revision configured in your channels, and put it into your path\npython --version # Python 3.9.9 which python # /nix/store/rppr9s436950i1dlzknbmz40m2xqqnxc-python3-3.9.9/bin/python Further reading # Please, also consult this posts, to learn more about Nix:\nAlexander Bantyev - What is Nix? (written) Burke Libbey - Nix: What Even is it Though (video) Harikrishnan R - \u0026lsquo;Why you should never ever use NixOS\u0026rsquo;: a rebuttal (written) ","date":"5 January 2022","permalink":"/blog/nix-intro/","section":"Blog","summary":"A short introduction to what is Nix, how it works, and what it can do for you","title":"Into the Nix"},{"content":"This is the advanced tag. Just like other listing pages in Congo, you can add custom content to individual taxonomy terms and it will be displayed at the top of the term listing. üöÄ\nYou can also use these content pages to define Hugo metadata like titles and descriptions that will be used for SEO and other purposes.\n","date":"1 January 0001","permalink":"/tags/advanced/","section":"Tags","summary":"This is the advanced tag.","title":"advanced"}]